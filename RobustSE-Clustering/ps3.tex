% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Problem Set 3},
  pdfauthor={Experiments and Causality},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Problem Set 3}
\author{Experiments and Causality}
\date{}

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# load packages }
\KeywordTok{library}\NormalTok{(data.table)}
\KeywordTok{library}\NormalTok{(foreign)}
\end{Highlighting}
\end{Shaded}

\hypertarget{write-functions}{%
\section{0. Write Functions}\label{write-functions}}

You're going to be doing a few things a \emph{number} of times --
calculating robust standard errors, calculating clustered standard
errors, and then calculating the confidence intervals that are built off
these standard errors.

\emph{After} you've worked through a few of these questions, I suspect
you will see places to write a function that will do this work for you.
Include those functions here, if you write them.

\hypertarget{replicate-results}{%
\section{1. Replicate Results}\label{replicate-results}}

Skim \href{./readings/brookman_green_ps3.pdf}{Broockman and Green's}
paper on the effects of Facebook ads and download an anonymized version
of the data for Facebook users only.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d <-}\StringTok{ }\KeywordTok{fread}\NormalTok{(}\StringTok{"./data/broockman_green_anon_pooled_fb_users_only.csv"}\NormalTok{)}

\NormalTok{dt <-}\StringTok{ }\KeywordTok{data.table}\NormalTok{(d)}
\KeywordTok{head}\NormalTok{(dt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    studyno treat_ad                   cluster name_recall positive_impression
## 1:       2        0 Study 2, Cluster Number 1           0                   0
## 2:       2        0 Study 2, Cluster Number 2           1                   0
## 3:       2        0 Study 2, Cluster Number 3           0                   0
## 4:       2        0 Study 2, Cluster Number 4           1                   0
## 5:       2        1 Study 2, Cluster Number 7           1                   1
## 6:       2        1 Study 2, Cluster Number 7           0                   0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using regression without clustered standard errors (that is, ignoring
  the clustered assignment), compute a confidence interval for the
  effect of the ad on candidate name recognition in Study 1 only (the
  dependent variable is \texttt{name\_recall}).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \textbf{Note}: Ignore the blocking the article mentions throughout
  this problem.
\item
  \textbf{Note}: You will estimate something different than is reported
  in the study.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Run a regression without clustered standard errors}
\NormalTok{lin_mod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(name_recall }\OperatorTok{~}\StringTok{ }\NormalTok{positive_impression, }\DataTypeTok{data =}\NormalTok{ dt[studyno }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{])}
\KeywordTok{summary}\NormalTok{(lin_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = name_recall ~ positive_impression, data = dt[studyno == 
##     1])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.05312 -0.05312 -0.05312 -0.05312  0.94688 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)         0.053120   0.006077   8.741   <2e-16 ***
## positive_impression 0.946880   0.016822  56.287   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2093 on 1362 degrees of freedom
## Multiple R-squared:  0.6994, Adjusted R-squared:  0.6991 
## F-statistic:  3168 on 1 and 1362 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Compute the confidence interval for the effect of the ad on the candidate name recognition}
\NormalTok{p1_confint <-}\StringTok{ }\KeywordTok{confint}\NormalTok{(lin_mod,}\StringTok{"positive_impression"}\NormalTok{,}\DataTypeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Answer:} The 95\% confidence interval is {[} 0.9138799 ,
0.9798806.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What are the clusters in Broockman and Green's study? Why might taking
  clustering into account increase the standard errors?
\end{enumerate}

\begin{quote}
Answer here.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Estimate a regression that estimates the effect of the ad on candidate
  name recognition in Study 1, but this time take take clustering into
  account when you compute the standard errors.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  The estimation of the \emph{model} does not change, only the
  estimation of the standard errors.
\item
  You can estimate these clustered standard errors using
  \texttt{sandwich::vcovCL}, which means: "The \texttt{vcovCL} function
  from the \texttt{sandwich} package.
\item
  We talk about this more in code that is availbe in the course repo.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  Change the context: estimate the treatment effect in Study 2, using
  clustered standard errors. If you've written your code for part 3
  carefully, you should be able to simply change the row-scoping that
  you're calling. If you didn't write it carefully, for legibility for
  your colleagues, you might consider re-writting your solution to the
  last question.
\item
  Run a regression to test for the effect of the ad on candidate name
  recognition, but this time use the entire sample from both studies --
  do not take into account which study the data is from (more on this in
  a moment), but just ``pool'' the data.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Does this estimate tell you anything useful?
\item
  Why or why not?
\item
  Can you say that the treatment assignment procedure used is fully
  random when you estimate this model? Or is there some endogeneous
  process that could be confounding your estimate?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Estimate a model that uses all the data, but this time include a
  variable that identifies whether an observation was generated during
  Study 1 or Study 2.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  What is estimated in the ``Study 2 Fixed Effect''?
\item
  What is the treatment effect estimate and associated p-value?
\item
  Think a little bit more about the treatment effect that you've
  estimated: Can this treatment effect, as you've entered it in the
  model be \emph{different} between Study 1 and Study 2?
\item
  Why or why not?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Estimate a model that lets the treatment effects be different between
  Study 1 and Study 2. With this model, conduct a formal test -- it must
  have a p-value associated with the test -- for whether the treatment
  effects are different in Study 1 than Study 2.
\end{enumerate}

\hypertarget{peruvian-recycling}{%
\section{2. Peruvian Recycling}\label{peruvian-recycling}}

Look at \href{./readings/recycling_peru.pdf}{this article} about
encouraging recycling in Peru. The paper contains two experiments, a
``participation study'' and a ``participation intensity study.'' In this
problem, we will focus on the latter study, whose results are contained
in Table 4 in this problem. You will need to read the relevant section
of the paper (starting on page 20 of the manuscript) in order to
understand the experimental design and variables. (\emph{Note that
``indicator variable'' is a synonym for ``dummy variable,'' in case you
haven't seen this language before.})

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In Column 3 of Table 4A, what is the estimated ATE of providing a
  recycling bin on the average weight of recyclables turned in per
  household per week, during the six-week treatment period? Provide a
  95\% confidence interval.
\item
  In Column 3 of Table 4A, what is the estimated ATE of sending a text
  message reminder on the average weight of recyclables turned in per
  household per week? Provide a 95\% confidence interval.
\item
  Which outcome measures in Table 4A show statistically significant
  effects (at the 5\% level) of providing a recycling bin?
\item
  Which outcome measures in Table 4A show statistically significant
  effects (at the 5\% level) of sending text messages?
\item
  Suppose that, during the two weeks before treatment, household A turns
  in 2kg per week more recyclables than household B does, and suppose
  that both households are otherwise identical (including being in the
  same treatment group). From the model, how much more recycling do we
  predict household A to have than household B, per week, during the six
  weeks of treatment? Provide only a point estimate, as the confidence
  interval would be a bit complicated. This question is designed to test
  your understanding of slope coefficients in regression.
\item
  Suppose that the variable ``percentage of visits turned in bag,
  baseline'' had been left out of the regression reported in Column 1.
  What would you expect to happen to the results on providing a
  recycling bin? Would you expect an increase or decrease in the
  estimated ATE? Would you expect an increase or decrease in the
  standard error? Explain our reasoning.
\item
  In column 1 of Table 4A, would you say the variable ``has cell phone''
  is a bad control? Explain your reasoning.
\item
  If we were to remove the ``has cell phone'' variable from the
  regression, what would you expect to happen to the coefficient on
  ``Any SMS message''? Would it go up or down? Explain your reasoning.
\end{enumerate}

\hypertarget{multifactor-experiments}{%
\section{3. Multifactor Experiments}\label{multifactor-experiments}}

Staying with the same experiment, now lets think about multifactor
experiments.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the full experimental design for this experiment? Tell us the
  dimensions, such as 2x2x3. (Hint: the full results appear in Panel
  4B.)
\item
  In the results of Table 4B, describe the baseline category. That is,
  in English, how would you describe the attributes of the group of
  people for whom all dummy variables are equal to zero?
\item
  In column (1) of Table 4B, interpret the magnitude of the coefficient
  on ``bin without sticker.'' What does it mean?
\item
  In column (1) of Table 4B, which seems to have a stronger treatment
  effect, the recycling bin with message sticker, or the recycling bin
  without sticker? How large is the magnitude of the estimated
  difference?
\item
  Is this difference you just described statistically significant?
  Explain which piece of information in the table allows you to answer
  this question.
\item
  Notice that Table 4C is described as results from ``fully saturated''
  models. What does this mean? Looking at the list of variables in the
  table, explain in what sense the model is ``saturated.''
\end{enumerate}

\hypertarget{now-do-it-with-data}{%
\section{4. Now! Do it with data}\label{now-do-it-with-data}}

Download the data set for the recycling study in the previous problem,
obtained from the authors. We'll be focusing on the outcome variable
Y=``number of bins turned in per week'' (avg\_bins\_treat).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d <-}\StringTok{ }\KeywordTok{read.dta}\NormalTok{(}\StringTok{"./data/karlan_data_subset_for_class.dta"}\NormalTok{)}
\NormalTok{d <-}\StringTok{ }\KeywordTok{data.table}\NormalTok{(d)}
\KeywordTok{head}\NormalTok{(d)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    street havecell avg_bins_treat base_avg_bins_treat bin sms bin_s bin_g sms_p
## 1:      7        1      1.0416666               0.750   1   1     1     0     0
## 2:      7        1      0.0000000               0.000   0   1     0     0     1
## 3:      7        1      0.7500000               0.500   0   0     0     0     0
## 4:      7        1      0.5416667               0.500   0   0     0     0     0
## 5:      6        1      0.9583333               0.375   1   0     0     1     0
## 6:      8        0      0.2083333               0.000   1   0     0     1     0
##    sms_g
## 1:     1
## 2:     0
## 3:     0
## 4:     0
## 5:     0
## 6:     0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Do some quick exploratory data analysis with this data. There are some values in this data that seem a bit strange. Determine what these are, and figure out what you would like to do with them. Also, notice what happens with your estimates vis-a-vis the estimates that are produced by the authors when you do something sensible with this strange values. }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For simplicity, let's start by measuring the effect of providing a
  recycling bin, ignoring the SMS message treatment (and ignoring
  whether there was a sticker on the bin or not). Run a regression of Y
  on only the bin treatment dummy, so you estimate a simple difference
  in means. Provide a 95\% confidence interval for the treatment effect.
\item
  Now add the pre-treatment value of Y as a covariate. Provide a 95\%
  confidence interval for the treatment effect. Explain how and why this
  confidence interval differs from the previous one.
\item
  Now add the street fixed effects. (You'll need to use the R command
  factor().) Provide a 95\% confidence interval for the treatment
  effect.
\item
  Recall that the authors described their experiment as ``stratified at
  the street level,'' which is a synonym for blocking by street. Explain
  why the confidence interval with fixed effects does not differ much
  from the previous one.
\item
  Perhaps having a cell phone helps explain the level of recycling
  behavior. Instead of ``has cell phone,'' we find it easier to
  interpret the coefficient if we define the variable " no cell phone."
  Give the R command to define this new variable, which equals one minus
  the ``has cell phone'' variable in the authors' data set. Use ``no
  cell phone'' instead of ``has cell phone'' in subsequent regressions
  with this dataset.
\item
  Now add ``no cell phone'' as a covariate to the previous regression.
  Provide a 95\% confidence interval for the treatment effect. Explain
  why this confidence interval does not differ much from the previous
  one.
\item
  Now let's add in the SMS treatment. Re-run the previous regression
  with ``any SMS'' included. You should get the same results as in Table
  4A. Provide a 95\% confidence interval for the treatment effect of the
  recycling bin. Explain why this confidence interval does not differ
  much from the previous one.
\item
  Now reproduce the results of column 2 in Table 4B, estimating separate
  treatment effects for the two types of SMS treatments and the two
  types of recycling-bin treatments. Provide a 95\% confidence interval
  for the effect of the unadorned recycling bin. Explain how your answer
  differs from that in part (g), and explain why you think it differs.
\end{enumerate}

\hypertarget{a-final-practice-problem}{%
\section{5. A Final Practice Problem}\label{a-final-practice-problem}}

Now for a fictional scenario. An emergency two-week randomized
controlled trial of the experimental drug ZMapp is conducted to treat
Ebola. (The control represents the usual standard of care for patients
identified with Ebola, while the treatment is the usual standard of care
plus the drug.)

Here are the (fake) data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d <-}\StringTok{ }\KeywordTok{fread}\NormalTok{(}\StringTok{"./data/Ebola_rct2.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(d)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    temperature_day0 vomiting_day0 treat_zmapp temperature_day14 vomiting_day14
## 1:         99.53168             1           0          98.62634              1
## 2:         97.37372             0           0          98.03251              1
## 3:         97.00747             0           1          97.93340              0
## 4:         99.74761             1           0          98.40457              1
## 5:         99.57559             1           1          99.31678              1
## 6:         98.28889             1           1          99.82623              1
##    male
## 1:    0
## 2:    0
## 3:    1
## 4:    0
## 5:    0
## 6:    1
\end{verbatim}

You are asked to analyze it. Patients' temperature and whether they are
vomiting is recorded on day 0 of the experiment, then ZMapp is
administered to patients in the treatment group on day 1. Vomiting and
temperature is again recorded on day 14.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Without using any covariates, answer this question with regression:
  What is the estimated effect of ZMapp (with standard error in
  parentheses) on whether someone was vomiting on day 14? What is the
  p-value associated with this estimate?
\item
  Add covariates for vomiting on day 0 and patient temperature on day 0
  to the regression from part (a) and report the ATE (with standard
  error). Also report the p-value.
\item
  Do you prefer the estimate of the ATE reported in part (a) or part
  (b)? Why? Report the results of the F-test that you used to form this
  opinion.
\item
  The regression from part (b) suggests that temperature is highly
  predictive of vomiting. Also include temperature on day 14 as a
  covariate in the regression from part (b) and report the ATE, the
  standard error, and the p-value.
\item
  Do you prefer the estimate of the ATE reported in part (b) or part
  (d)? Why?
\item
  Now let's switch from the outcome of vomiting to the outcome of
  temperature, and use the same regression covariates as in part (b).
  Test the hypothesis that ZMapp is especially likely to reduce mens'
  temperatures, as compared to womens', and describe how you did so.
  What do the results suggest?
\item
  Suspend reality for just a moment -- suppose that you had the option
  of being a man or a woman who was a part of this study. Based on this
  data, which sex would you rather be? This time, you need to produce
  evidence (probably from your model estimates) to inform your
  determination. What does your determination depend on?
\item
  Suppose that you had not run the regression in part (f). Instead, you
  speak with a colleague to learn about heterogeneous treatment effects.
  This colleague has access to a non-anonymized version of the same
  dataset and reports that he had looked at heterogeneous effects of the
  ZMapp treatment by each of 10,000 different covariates to examine
  whether each predicted the effectiveness of ZMapp on each of 2,000
  different indicators of health, for 20,000,000 different regressions
  in total. Across these 20,000,000 regressions your colleague ran, the
  treatment's interaction with gender on the outcome of temperature is
  the only heterogeneous treatment effect that he found to be
  statistically significant. He reasons that this shows the importance
  of gender for understanding the effectiveness of the drug, because
  nothing else seemed to indicate why it worked. Bolstering his
  confidence, after looking at the data, he also returned to his medical
  textbooks and built a theory about why ZMapp interacts with processes
  only present in men to cure. Another doctor, unfamiliar with the data,
  hears his theory and finds it plausible. How likely do you think it is
  ZMapp works especially well for curing Ebola in men, and why? (This
  question is conceptual can be answered without performing any
  computation.)
\item
  Now, imagine that what described in part (7) did not happen, but that
  you had tested this heterogeneous treatment effect, and only this
  heterogeneous treatment effect, of your own accord. Would you be more
  or less inclined to believe that the heterogeneous treatment effect
  really exists? Why?
\item
  Another colleague proposes that being of African descent causes one to
  be more likely to get Ebola. He asks you what ideal experiment would
  answer this question. What would you tell him? (\emph{Hint: refer to
  Chapter 1 of Mostly Harmless Econometrics.})
\end{enumerate}

\end{document}
